{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jossy450/invitro-fertilization-prediction/blob/main/ivf_med_prediction_codes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7030d2aa",
      "metadata": {
        "id": "7030d2aa"
      },
      "outputs": [],
      "source": [
        "#importing required packages\n",
        "#modelues for EDA steps\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d691553c",
      "metadata": {
        "id": "d691553c"
      },
      "outputs": [],
      "source": [
        "\n",
        "#modules for data cleaning and data analysis\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import scipy.stats as stats\n",
        "\n",
        "#modules for model building\n",
        "#algorithms for sampling\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "#baseline linear model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "#modules for hyper parameter tuning\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#modules for model evaluation\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import precision_score, accuracy_score, f1_score, r2_score\n",
        "from sklearn.metrics import precision_recall_curve, roc_curve\n",
        "#modules for avoiding warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#setting backend for matplotlib\n",
        "%matplotlib inline\n",
        "#setting formatting options\n",
        "pd.options.display.max_columns = 100\n",
        "pd.options.display.max_rows = 900\n",
        "pd.set_option('float_format' , '{:f}'.format)\n",
        "#setting plot style\n",
        "plt.style.use('seaborn-darkgrid')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ebe8fc1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "2ebe8fc1",
        "outputId": "232b5696-1606-49e5-a1fc-ff5a9edc3c6c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-e1ebdaf2224f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#load the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/ivf.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#print the top 5 record of the IVF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/ivf.csv'"
          ]
        }
      ],
      "source": [
        "#load the dataset\n",
        "df = pd.read_csv(\"/content/ivf.csv\")\n",
        "#print the top 5 record of the IVF\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75a4368a",
      "metadata": {
        "id": "75a4368a"
      },
      "outputs": [],
      "source": [
        "#check the shape of the dataset\n",
        "df.shape\n",
        "#using value_counts() on the live birth occurence\n",
        "df['Live Birth Occurrence'].value_counts()\n",
        "# Fill missing values with 0 live birth\n",
        "df['Live Birth Occurrence'] = df['Live Birth Occurrence'].fillna(0)\n",
        "df['Live Birth Occurrence'] = df['Live Birth Occurrence'].astype(int)\n",
        "#check the columns\n",
        "df.columns\n",
        "#checking for missing values\n",
        "df.isnull().sum()\n",
        "# Handle missing values\n",
        "# Drop columns with a large number of missing values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70a2ddb8",
      "metadata": {
        "id": "70a2ddb8"
      },
      "outputs": [],
      "source": [
        "threshold = len(df) * 0.5  # Set a threshold for missing values\n",
        "df.dropna(thresh=threshold, axis=1, inplace=True)\n",
        "# Impute missing values in numerical columns with mean\n",
        "numerical_columns = df.select_dtypes(include='number').columns\n",
        "df[numerical_columns] = df[numerical_columns].fillna(df[numerical_columns].mean())\n",
        "# Impute missing values in categorical columns with mode\n",
        "categorical_columns = df.select_dtypes(include='object').columns\n",
        "df[categorical_columns] = df[categorical_columns].fillna(df[categorical_columns].mode().iloc[0])\n",
        "df.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c01b09a",
      "metadata": {
        "id": "2c01b09a"
      },
      "source": [
        "# Perform exploratory data analysis (EDA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e99c0568",
      "metadata": {
        "id": "e99c0568"
      },
      "outputs": [],
      "source": [
        "# Plot distribution of the target variable\n",
        "sns.countplot(x='Live Birth Occurrence', data=df)\n",
        "plt.title('Distribution of Live Birth Occurrence')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5a953c6",
      "metadata": {
        "id": "e5a953c6"
      },
      "outputs": [],
      "source": [
        "\n",
        "df.columns\n",
        "df['Patient Age at Treatment'].value_counts()\n",
        "\n",
        "# Age intervals and their respective counts\n",
        "age_intervals = ['18-34', '35-37', '38-39', '40-42', '43-44', '45-50']\n",
        "counts = [66316, 35679, 21817, 21459, 6912, 3948]\n",
        "\n",
        "# Define a color palette\n",
        "colors = ['skyblue', 'lightgreen', 'orange', 'salmon', 'purple', 'yellow']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26b60084",
      "metadata": {
        "id": "26b60084"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Plot the distribution using a bar plot with the specified color palette\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=age_intervals, y=counts, palette=colors)\n",
        "plt.xlabel('Age Intervals')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Distribution of Patient Age at Treatment')\n",
        "\n",
        "# Add the legend\n",
        "for index, value in enumerate(counts):\n",
        " plt.text(index, value, str(value), ha='center', va='bottom', fontsize=10)\n",
        "plt.savefig('distribution_age_at_treatment_barplot.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d83c321",
      "metadata": {
        "id": "3d83c321"
      },
      "outputs": [],
      "source": [
        "# Plotting a bar chart of infertility types\n",
        "infertility_cols = ['Type of Infertility - Female Primary', 'Type of Infertility - Female Secondary',\n",
        "                    'Type of Infertility - Male Primary', 'Type of Infertility - Male Secondary',\n",
        "                    'Type of Infertility -Couple Primary', 'Type of Infertility -Couple Secondary']\n",
        "infertility_counts = df[infertility_cols].sum()\n",
        "ax = sns.barplot(x=infertility_counts.index, y=infertility_counts.values)\n",
        "plt.xlabel('Infertility Type')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Distribution of Infertility Types')\n",
        "plt.xticks(rotation=45)\n",
        "# Placing x-axis labels under the bars\n",
        "ax.set_xticklabels(infertility_counts.index, rotation=45, ha='right')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e3ab89e",
      "metadata": {
        "id": "0e3ab89e"
      },
      "outputs": [],
      "source": [
        "previous_cycles_cols = ['Total Number of Previous IVF cycles', 'Total Number of Previous DI cycles']\n",
        "previous_cycles_counts = df[previous_cycles_cols].sum()\n",
        "previous_cycles_counts = previous_cycles_counts.str.extract('(\\d+)').astype(float)\n",
        "# Plotting a stacked bar chart of previous IVF and DI cycles\n",
        "ax = sns.barplot(x=previous_cycles_counts.index, y=previous_cycles_counts.values.flatten())\n",
        "plt.xlabel('Cycle Type')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Distribution of Previous IVF and DI Cycles')\n",
        "plt.xticks(rotation=45)\n",
        "ax.set_xticklabels(previous_cycles_counts.index, rotation=45, ha='right')\n",
        "plt.show()\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cbd558e",
      "metadata": {
        "id": "1cbd558e"
      },
      "outputs": [],
      "source": [
        "# Plotting a count plot of infertility causes\n",
        "cause_cols = ['Cause  of Infertility - Tubal disease',\n",
        "       'Cause of Infertility - Ovulatory Disorder',\n",
        "       'Cause of Infertility - Male Factor',\n",
        "       'Cause of Infertility - Patient Unexplained',\n",
        "       'Cause of Infertility - Endometriosis',\n",
        "       'Cause of Infertility - Cervical factors',\n",
        "       'Cause of Infertility - Female Factors',\n",
        "       'Cause of Infertility - Partner Sperm Concentration',\n",
        "       'Cause of Infertility -  Partner Sperm Morphology',\n",
        "       'Causes of Infertility - Partner Sperm Motility',\n",
        "       'Cause of Infertility -  Partner Sperm Immunological factors']\n",
        "cause_counts = df[cause_cols].sum()\n",
        "ax = sns.barplot(x=cause_counts.index, y=cause_counts.values)\n",
        "plt.xlabel('Infertility Cause')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Distribution of Infertility Causes')\n",
        "plt.savefig('infertilitycauses.png')\n",
        "plt.xticks(rotation=45)\n",
        "# Placing x-axis labels under the bars\n",
        "ax.set_xticklabels(cause_counts.index, rotation=45, ha='right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02230678",
      "metadata": {
        "id": "02230678"
      },
      "outputs": [],
      "source": [
        "# Plotting a stacked bar plot of treatment type and live birth occurrence\n",
        "treatment_type_counts = df['Type of treatment - IVF or DI'].value_counts()\n",
        "treatment_occurrence_counts = df.groupby('Type of treatment - IVF or DI')['Live Birth Occurrence'].sum()\n",
        "df_plot = pd.DataFrame({'Treatment Type': treatment_type_counts.index,\n",
        "                        'Not Successful': treatment_type_counts.values - treatment_occurrence_counts.values,\n",
        "                        'Successful': treatment_occurrence_counts.values})\n",
        "df_plot.set_index('Treatment Type', inplace=True)\n",
        "df_plot.plot(kind='bar', stacked=True)\n",
        "plt.xlabel('Treatment Type')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Live Birth Occurrence by Treatment Type')\n",
        "plt.xticks(rotation=0)\n",
        "plt.legend()\n",
        "plt.savefig('occurence with treatment.png')\n",
        "plt.show()\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(data=df, x='Stimulation used', hue='Live Birth Occurrence')\n",
        "plt.xlabel('Stimulation Used')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Impact of Stimulation Used on Live Birth Occurrence')\n",
        "plt.legend(title='Live Birth')\n",
        "plt.savefig('simulated.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "909ad62f",
      "metadata": {
        "id": "909ad62f"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(data=df, x='Donated embryo', hue='Live Birth Occurrence')\n",
        "plt.xlabel('Donated Embryo')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Examination of Donor Embryos on Live Birth Occurrence')\n",
        "plt.legend(title='Live Birth')\n",
        "plt.show()\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(data=df, x='Type of treatment - IVF or DI', hue='Specific treatment type')\n",
        "plt.xlabel('Treatment Type')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Analysis of Treatment Types and Specific Treatment')\n",
        "plt.legend(title='Specific Treatment')\n",
        "plt.show()\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.countplot(data=df, x='Year of Treatment', hue='Live Birth Occurrence')\n",
        "plt.xlabel('Year of Treatment')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Distribution of Live Birth Occurrence by Year of Treatment')\n",
        "plt.legend(title='Live Birth')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(data=df, x='Frozen Cycle', hue='Live Birth Occurrence')\n",
        "plt.xlabel('Cycle Type')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Proportion of Fresh vs. Frozen Cycles in Live Birth Occurrence')\n",
        "plt.legend(title='Live Birth')\n",
        "plt.show()\n",
        "df['Elective Single Embryo Transfer'].value_counts()\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(data=df, x='Elective Single Embryo Transfer', hue='Live Birth Occurrence')\n",
        "plt.xlabel('Elective Single Embryo Transfer')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Comparison of Live Birth Occurrence between eSET and Other Transfer Types')\n",
        "plt.legend(title='Live Birth')\n",
        "plt.show()\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(data=df, x='Egg Source', hue='Number of Live Births')\n",
        "plt.xlabel('Egg Source')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Analysis of Live Births by Egg Source')\n",
        "plt.legend(title='Number of Live Births')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "df.head()\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "822019e6",
      "metadata": {
        "id": "822019e6"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c97e9a7",
      "metadata": {
        "id": "3c97e9a7"
      },
      "outputs": [],
      "source": [
        "# Define a list of features that are related to infertility causes\n",
        "infertility_causes_features = [\n",
        "    'Type of Infertility - Female Primary',\n",
        "    'Type of Infertility - Female Secondary',\n",
        "    'Type of Infertility - Male Primary',\n",
        "    'Type of Infertility - Male Secondary',\n",
        "    'Type of Infertility -Couple Primary',\n",
        "    'Type of Infertility -Couple Secondary',\n",
        "    'Cause  of Infertility - Tubal disease',\n",
        "    'Cause of Infertility - Ovulatory Disorder',\n",
        "    'Cause of Infertility - Male Factor',\n",
        "    'Cause of Infertility - Patient Unexplained',\n",
        "    'Cause of Infertility - Endometriosis',\n",
        "    'Cause of Infertility - Cervical factors',\n",
        "    'Cause of Infertility - Female Factors',\n",
        "    'Cause of Infertility - Partner Sperm Concentration',\n",
        "    'Cause of Infertility -  Partner Sperm Morphology',\n",
        "    'Causes of Infertility - Partner Sperm Motility',\n",
        "    'Cause of Infertility -  Partner Sperm Immunological factors',\n",
        "     'Main Reason for Producing Embroys Storing Eggs',\n",
        "    'Type of Ovulation Induction',\n",
        "    'Donated embryo',\n",
        "    'Patient acting as Surrogate',\n",
        "    'Specific treatment type',\n",
        "    'PGD', 'Patient Age at Treatment'\n",
        "]\n",
        "# Splitting the data into features (X) and target (y)\n",
        "X = df[infertility_causes_features]\n",
        "y = df['Live Birth Occurrence']\n",
        "# Perform label encoding for categorical variables\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    X[col] = le.fit_transform(X[col])\n",
        "# Perform normalization on numerical variables\n",
        "numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "scaler = MinMaxScaler()\n",
        "X[numeric_cols] = scaler.fit_transform(X[numeric_cols])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33c34dec",
      "metadata": {
        "id": "33c34dec"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Perform SMOTE to handle class imbalance\n",
        "smote = RandomUnderSampler()\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "# Convert the resampled target array to a DataFrame\n",
        "y_resampled_df = pd.DataFrame(y_resampled, columns=['Live Birth Occurrence'])\n",
        "# Check the value distribution\n",
        "value_counts = y_resampled_df['Live Birth Occurrence'].value_counts()\n",
        "print(value_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a38f12d",
      "metadata": {
        "id": "6a38f12d"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Train Decision Tree Model\n",
        "model = DecisionTreeClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# List of columns representing different feature categories\n",
        "feature_columns = ['Patient Age at Treatment', 'Type of Infertility - Female Primary', 'Type of Infertility - Female Secondary',\n",
        "                   'Type of Infertility - Male Primary', 'Type of Infertility - Male Secondary',\n",
        "                   'Type of Infertility -Couple Primary', 'Type of Infertility -Couple Secondary',\n",
        "                   'Cause  of Infertility - Tubal disease', 'Cause of Infertility - Ovulatory Disorder',\n",
        "                   'Cause of Infertility - Male Factor', 'Cause of Infertility - Patient Unexplained',\n",
        "                   'Cause of Infertility - Endometriosis', 'Cause of Infertility - Cervical factors',\n",
        "                   'Cause of Infertility - Female Factors', 'Cause of Infertility - Partner Sperm Concentration',\n",
        "                   'Cause of Infertility -  Partner Sperm Morphology', 'Causes of Infertility - Partner Sperm Motility',\n",
        "                   'Cause of Infertility -  Partner Sperm Immunological factors', 'Main Reason for Producing Embroys Storing Eggs',\n",
        "                   'Type of Ovulation Induction', 'Donated embryo', 'Patient acting as Surrogate',\n",
        "                   'Specific treatment type', 'PGD']\n",
        "\n",
        "# Dictionary to store metrics for each feature category\n",
        "feature_metrics = {}\n",
        "\n",
        "# Loop through each feature column\n",
        "for column in feature_columns:\n",
        "    # Subset data based on the feature category\n",
        "    subset_metrics = {}\n",
        "    for category in X_test[column].unique():\n",
        "        subset_indices = X_test[column] == category\n",
        "        subset_X = X_test[subset_indices]\n",
        "        subset_y = y_test[subset_indices]\n",
        "\n",
        "        # Skip calculation if there's only one class in the subset\n",
        "        if len(np.unique(subset_y)) == 1:\n",
        "            continue\n",
        "\n",
        "        # Calculate metrics\n",
        "        y_pred = model.predict(subset_X)\n",
        "        tp = confusion_matrix(subset_y, y_pred)[1, 1]\n",
        "        fp = confusion_matrix(subset_y, y_pred)[0, 1]\n",
        "        precision = precision_score(subset_y, y_pred)\n",
        "        recall = recall_score(subset_y, y_pred)\n",
        "\n",
        "        subset_metrics[category] = {'TP': tp, 'FP': fp, 'Precision': precision, 'Recall': recall}\n",
        "\n",
        "    feature_metrics[column] = subset_metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4158584f",
      "metadata": {
        "id": "4158584f"
      },
      "outputs": [],
      "source": [
        "# Now feature_metrics dictionary contains metrics for each feature category\n",
        "# You can analyze and visualize the results as needed\n",
        "# Loop through each feature column and its associated metrics\n",
        "for column, metrics in feature_metrics.items():\n",
        "    print(f\"Feature: {column}\")\n",
        "    for category, metric_values in metrics.items():\n",
        "        print(f\"Category: {category}\")\n",
        "        print(f\"TP: {metric_values['TP']}\")\n",
        "        print(f\"FP: {metric_values['FP']}\")\n",
        "        print(f\"Precision: {metric_values['Precision']}\")\n",
        "        print(f\"Recall: {metric_values['Recall']}\")\n",
        "        print(\"----------------------\")\n",
        "\n",
        "# Plotting examples (you can customize this based on your needs)\n",
        "for column, metrics in feature_metrics.items():\n",
        "    categories = list(metrics.keys())\n",
        "    precisions = [metric['Precision'] for metric in metrics.values()]\n",
        "    recalls = [metric['Recall'] for metric in metrics.values()]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(categories, precisions, label='Precision')\n",
        "    plt.bar(categories, recalls, label='Recall', alpha=0.5)\n",
        "    plt.xlabel('Categories')\n",
        "    plt.ylabel('Metrics')\n",
        "    plt.title(f'Metrics for Feature: {column}')\n",
        "    plt.legend()\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d61ad6ad",
      "metadata": {
        "id": "d61ad6ad"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Loop through each feature column and its associated metrics\n",
        "for column, metrics in feature_metrics.items():\n",
        "    print(f\"Feature: {column}\")\n",
        "\n",
        "    # Extract the encoded categories from the metrics\n",
        "    encoded_categories = list(metrics.keys())\n",
        "\n",
        "    # Convert encoded categories to integers\n",
        "    encoded_categories = [int(round(category)) for category in encoded_categories]\n",
        "\n",
        "    # Fit a new LabelEncoder to the original categorical values\n",
        "    label_encoder = LabelEncoder()\n",
        "    label_encoder.fit(df[column])\n",
        "\n",
        "    # Reverse encode the categories to their original values\n",
        "    original_categories = label_encoder.inverse_transform(encoded_categories)\n",
        "\n",
        "    for category, metric_values in metrics.items():\n",
        "        original_category = original_categories[encoded_categories.index(int(round(category)))]\n",
        "        print(f\"Original Category: {original_category}\")\n",
        "        print(f\"TP: {metric_values['TP']}\")\n",
        "        print(f\"FP: {metric_values['FP']}\")\n",
        "        print(f\"Precision: {metric_values['Precision']}\")\n",
        "        print(f\"Recall: {metric_values['Recall']}\")\n",
        "        print(\"----------------------\")\n",
        "\n",
        "# Plotting examples (similar to previous code)\n",
        "for column, metrics in feature_metrics.items():\n",
        "    label_encoder = LabelEncoder()\n",
        "    label_encoder.fit(df[column])\n",
        "\n",
        "    encoded_categories = list(metrics.keys())\n",
        "    encoded_categories = [int(round(category)) for category in encoded_categories]\n",
        "\n",
        "    original_categories = label_encoder.inverse_transform(encoded_categories)\n",
        "\n",
        "    precisions = [metric['Precision'] for metric in metrics.values()]\n",
        "    recalls = [metric['Recall'] for metric in metrics.values()]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(original_categories, precisions, label='Precision')\n",
        "    plt.bar(original_categories, recalls, label='Recall', alpha=0.5)\n",
        "    plt.xlabel('Categories')\n",
        "    plt.ylabel('Metrics')\n",
        "    plt.title(f'Metrics for Feature: {column}')\n",
        "    plt.legend()\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59bd7359",
      "metadata": {
        "id": "59bd7359"
      },
      "outputs": [],
      "source": [
        "# Initialize the models\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "from sklearn.model_selection import cross_val_score\n",
        "# Fit the Random Forest model\n",
        "rf_model.fit(X_resampled, y_resampled)\n",
        "# Get feature importances from the model\n",
        "feature_importances = rf_model.feature_importances_\n",
        "# Create a DataFrame to associate features with their importances\n",
        "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
        "# Sort the features by importance in descending order\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "# Select the top 10 most important features\n",
        "top_features = feature_importance_df.head(5)['Feature'].tolist()\n",
        "# Filter the data to keep only the top features\n",
        "X_top_features = X_resampled[top_features]\n",
        "# Initialize the Random Forest model with the top features\n",
        "rf_model_top = RandomForestClassifier(random_state=42)\n",
        "# Perform cross-validation on the model with top features\n",
        "rf_scores_top = cross_val_score(rf_model_top, X_top_features, y_resampled, cv=5, scoring='accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ce003c7",
      "metadata": {
        "id": "7ce003c7"
      },
      "outputs": [],
      "source": [
        "# Print cross-validation scores\n",
        "print(\"Random Forest CV Scores (Top Features):\", rf_scores_top)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa252c8b",
      "metadata": {
        "id": "fa252c8b"
      },
      "outputs": [],
      "source": [
        "# Initialize the models\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "svm_model = SVC(random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbc17d47",
      "metadata": {
        "id": "dbc17d47"
      },
      "outputs": [],
      "source": [
        "# List of models and their names\n",
        "models = [rf_model, dt_model, svm_model]\n",
        "model_names = ['Random Forest', 'Decision Tree', 'SVM']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1db93496",
      "metadata": {
        "id": "1db93496"
      },
      "outputs": [],
      "source": [
        "# Loop through the models\n",
        "for model, name in zip(models, model_names):\n",
        "    # Perform k-fold cross-validation and predict on the whole dataset\n",
        "    y_pred = cross_val_predict(model, X_resampled, y_resampled, cv=5)\n",
        "      # Generate classification report\n",
        "    report = classification_report(y_resampled, y_pred)\n",
        "    print(f\"Classification Report for {name}:\\n{report}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "152bad99",
      "metadata": {
        "id": "152bad99"
      },
      "outputs": [],
      "source": [
        "# Generate synthetic data for demonstration\n",
        "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split( X_resampled, y_resampled, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac7a8d27",
      "metadata": {
        "id": "ac7a8d27"
      },
      "outputs": [],
      "source": [
        "# Initialize the models\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "svm_model = SVC(probability=True, random_state=42)  # Enable probability estimates for ROC curve\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6721ac32",
      "metadata": {
        "id": "6721ac32"
      },
      "outputs": [],
      "source": [
        "# List of models and their names\n",
        "models = [rf_model, dt_model, svm_model]\n",
        "model_names = ['Random Forest', 'Decision Tree', 'SVM']\n",
        "\n",
        "for model, name in zip(models, model_names):\n",
        "    # Perform k-fold cross-validation and predict on the whole dataset\n",
        "    y_pred = cross_val_predict(model, X_train, y_train, cv=5)\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(y_train, y_pred)\n",
        "    print(f\"Classification Report for {name}:\\n{report}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82dd9c76",
      "metadata": {
        "id": "82dd9c76"
      },
      "outputs": [],
      "source": [
        "# Plot ROC Curve and calculate AUC if model supports probability estimates\n",
        "    if hasattr(model, 'predict_proba'):\n",
        "        y_scores = cross_val_predict(model, X_train, y_train, cv=5, method='predict_proba')[:, 1]\n",
        "        fpr, tpr, thresholds = roc_curve(y_train, y_scores)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title(f'ROC Curve for {name}')\n",
        "        plt.legend(loc='lower right')\n",
        "        plt.show()\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_train, y_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title(f\"{name} Confusion Matrix\")\n",
        "    plt.colorbar()\n",
        "    class_names = [\"Non-Success\", \"Success\"]\n",
        "    tick_marks = np.arange(len(class_names))\n",
        "    plt.xticks(tick_marks, class_names, rotation=45)\n",
        "    plt.yticks(tick_marks, class_names)\n",
        "\n",
        "    for i in range(len(class_names)):\n",
        "        for j in range(len(class_names)):\n",
        "            plt.text(j, i, str(cm[i, j]), ha=\"center\", va=\"center\", color=\"white\" if cm[i, j] > cm.max() / 2 else \"black\")\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.show()\n",
        "    print(\"---------------------------------------------------\")\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64c2d9a5",
      "metadata": {
        "id": "64c2d9a5"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d412a5b",
      "metadata": {
        "id": "7d412a5b"
      },
      "outputs": [],
      "source": [
        "# Assuming you have loaded X_resampled and y_resampled\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the models\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "svm_model = SVC(probability=True, random_state=42)  # Enable probability estimates for ROC curve\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39fe1ca6",
      "metadata": {
        "id": "39fe1ca6"
      },
      "outputs": [],
      "source": [
        "# List of models and their names\n",
        "models = [rf_model, dt_model, svm_model]\n",
        "model_names = ['Random Forest', 'Decision Tree', 'SVM']\n",
        "\n",
        "for model, name in zip(models, model_names):\n",
        "    # Train the model on the training data\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions on both train and validation sets\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_val_pred = model.predict(X_val)\n",
        "\n",
        "    # Generate classification report for train and validation\n",
        "    train_report = classification_report(y_train, y_train_pred)\n",
        "    val_report = classification_report(y_val, y_val_pred)\n",
        "\n",
        "    print(f\"Classification Report for {name} (Train):\\n{train_report}\\n\")\n",
        "    print(f\"Classification Report for {name} (Validation):\\n{val_report}\\n\")\n",
        "\n",
        "    # Plot ROC Curve and calculate AUC if model supports probability estimates\n",
        "    if hasattr(model, 'predict_proba'):\n",
        "        y_train_scores = model.predict_proba(X_train)[:, 1]\n",
        "        y_val_scores = model.predict_proba(X_val)[:, 1]\n",
        "\n",
        "        fpr_train, tpr_train, thresholds_train = roc_curve(y_train, y_train_scores)\n",
        "        roc_auc_train = auc(fpr_train, tpr_train)\n",
        "\n",
        "        fpr_val, tpr_val, thresholds_val = roc_curve(y_val, y_val_scores)\n",
        "        roc_auc_val = auc(fpr_val, tpr_val)\n",
        "\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.plot(fpr_train, tpr_train, color='darkorange', lw=2, label=f'Train ROC curve (area = {roc_auc_train:.2f})')\n",
        "        plt.plot(fpr_val, tpr_val, color='green', lw=2, label=f'Validation ROC curve (area = {roc_auc_val:.2f})')\n",
        "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title(f'ROC Curve for {name}')\n",
        "        plt.legend(loc='lower right')\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f589123",
      "metadata": {
        "id": "2f589123"
      },
      "outputs": [],
      "source": [
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_val, y_val_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title(f\"{name} Confusion Matrix (Validation)\")\n",
        "    plt.colorbar()\n",
        "    class_names = [\"Failure\", \"Success\"]\n",
        "    tick_marks = np.arange(len(class_names))\n",
        "    plt.xticks(tick_marks, class_names, rotation=45)\n",
        "    plt.yticks(tick_marks, class_names)\n",
        "\n",
        "    for i in range(len(class_names)):\n",
        "        for j in range(len(class_names)):\n",
        "            plt.text(j, i, str(cm[i, j]), ha=\"center\", va=\"center\", color=\"white\" if cm[i, j] > cm.max() / 2 else \"black\")\n",
        "\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.show()\n",
        "\n",
        "    # Train and Validation Accuracy Plot\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(['Train Accuracy', 'Validation Accuracy'], [train_accuracy, val_accuracy])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "727d5759",
      "metadata": {
        "id": "727d5759"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27a5767c",
      "metadata": {
        "id": "27a5767c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37870e2a",
      "metadata": {
        "id": "37870e2a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e87da5d5",
      "metadata": {
        "id": "e87da5d5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}